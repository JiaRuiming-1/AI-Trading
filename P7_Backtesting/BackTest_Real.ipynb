{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "In this notebook, we will complete backtest which is the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from statistics import median\n",
    "from scipy.stats import gaussian_kde\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Factors\n",
    "We have factors store in csv file which process and combine from privious steps. Pick up backtest time from 2022.4 - 2022.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fundamental_df = pd.read_csv('tmp_factor.csv').iloc[:,1:]\n",
    "universe_raw = pd.read_csv('backtest.csv').iloc[:,1:]\n",
    "universe_raw['date'] = pd.to_datetime(universe_raw['trade_date'], format='%Y%m%d')\n",
    "universe = universe_raw.set_index(['date']).sort_values(by=['date'])\n",
    "universe = universe.fillna(method='ffill').fillna(0.)\n",
    "# only use from 2022.4 to 2023.3, here from 20220201 in order to generate risk model from history\n",
    "universe = universe.loc[universe['trade_date']>=20220101]\n",
    "universe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Alpha Factors\n",
    "We can try two method, rank add zscore or only zscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to fix excuteed in privious step\n",
    "base_field = ['ts_code','trade_date','industry','ts_code', 'close', 'log-ret', 'return_2q']\n",
    "normalized_filed = ['alpha_volume', 'alpha_atr',  'alpha_supertrend', 'alpha_skew2sentiment','alpha_winlos']\n",
    "alpha_field = ['alpha_volume', 'alpha_atr',  'alpha_supertrend', 'alpha_skew2sentiment', 'alpha_winlos', 'alpha_AI'] \n",
    "\n",
    "def normalize_data(df):\n",
    "    df[normalized_filed ] = df[normalized_filed]/abs(df[normalized_filed]).max(axis=0)\n",
    "    return df\n",
    "\n",
    "universe['alpha_supertrend'] = - universe['supertrend']\n",
    "universe[ normalized_filed ] = universe.groupby('trade_date')[normalized_filed ].apply(normalize_data)\n",
    "print(universe.shape)\n",
    "universe.loc[universe.ts_code=='688117.SH'].head()[alpha_field + ['trade_date','ts_code']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor Exposures and Factor Returns\n",
    "The facort values in cross section should view as a type of exposure. We can calculate factor returns bettwen exposures of each ticker and daily return. We also did this in backtestig animate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shif return 2 times\n",
    "all_factors = universe.copy(deep=True)\n",
    "all_factors = all_factors.sort_values(by=['date'])\n",
    "all_factors = all_factors.replace([np.inf, -np.inf], np.nan).fillna(0.)\n",
    "all_factors['returns_2'] = all_factors.groupby('ts_code')['log-ret'].shift(-2).fillna(method='ffill')\n",
    "print(universe.shape, all_factors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wins(x,a,b):\n",
    "    return np.where(x <= a,a, np.where(x >= b, b, x))\n",
    "\n",
    "def get_formula(factors, Y):\n",
    "    L = [\"0\"]\n",
    "    L.extend(factors)\n",
    "    return Y + \" ~ \" + \" + \".join(L)\n",
    "\n",
    "def factors_from_names(n, name):\n",
    "    return list(filter(lambda x: name in x, n))\n",
    "\n",
    "def estimate_factor_returns(df, name='alpha_'): \n",
    "    ## winsorize returns for fitting \n",
    "    estu = df.copy(deep=True)\n",
    "    estu['returns_2'] = wins(estu['returns_2'], -0.1, 0.1)\n",
    "    all_factors = factors_from_names(list(df), name)\n",
    "    form = get_formula(all_factors, \"returns_2\")\n",
    "    model = ols(form, data=estu)\n",
    "    results = model.fit()\n",
    "    return results\n",
    "\n",
    "estimate_factor_returns(all_factors.loc[all_factors['trade_date']==20220505]).params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "date_and_code = [ 'trade_date','ts_code', 'returns_2']\n",
    "calendar = all_factors.trade_date.unique() # int64\n",
    "alpha_df = all_factors[alpha_field + date_and_code]\n",
    "facret = {}\n",
    "for dt in tqdm(calendar, desc='regression factor returns'):\n",
    "    facret[dt] = estimate_factor_returns(alpha_df.loc[alpha_df['trade_date']==dt]).params\n",
    "facret[calendar[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Veiw Factor Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = all_factors.index.unique()\n",
    "facret_df = pd.DataFrame(index = date_list)\n",
    "\n",
    "for ii, dt in zip(calendar,date_list): \n",
    "    for alp in alpha_field: \n",
    "        facret_df.at[dt, alp] = facret[ii][alp]\n",
    "\n",
    "for column in facret_df.columns:\n",
    "    plt.plot(facret_df[column].cumsum(), label=column)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Factor Returns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA model\n",
    "We use PCA algorithm to estimate risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class RiskModel(object):\n",
    "    def __init__(self, returns, num_factor_exposures, ann_factor=252):\n",
    "        \n",
    "        self.num_factor_exposures = num_factor_exposures\n",
    "        self.pca = PCA(n_components=num_factor_exposures, svd_solver='full')\n",
    "        self.pca.fit(returns)\n",
    "        \n",
    "        self.factor_betas_ = self.factor_betas(self.pca, returns.columns.values, np.arange(num_factor_exposures))\n",
    "        self.factor_returns_ = self.factor_returns(self.pca, returns, returns.index, np.arange(num_factor_exposures))\n",
    "        self.factor_cov_matrix_ = self.factor_cov_matrix(self.factor_returns_, ann_factor)\n",
    "        \n",
    "        self.idiosyncratic_var_matrix_ = self.idiosyncratic_var_matrix(returns, \n",
    "                                            self.factor_returns_, self.factor_betas_, ann_factor)\n",
    "        self.idiosyncratic_var_vector = pd.DataFrame(data=np.diag(self.idiosyncratic_var_matrix_),\n",
    "                                                     index=returns.columns)\n",
    "    \n",
    "    # got new exposure expressed by pca model\n",
    "    def factor_betas(self, pca, factor_beta_indices, factor_beta_columns):\n",
    "        return pd.DataFrame(pca.components_.T, factor_beta_indices, factor_beta_columns)\n",
    "    \n",
    "    # got new factor returns expressed by pca model\n",
    "    def factor_returns(self, pca, returns, factor_return_indices, factor_return_columns):\n",
    "        return pd.DataFrame(pca.transform(returns), factor_return_indices, factor_return_columns)\n",
    "    \n",
    "    # got new factor covariance matirx by pca expressed returns\n",
    "    def factor_cov_matrix(self, factor_returns, ann_factor):\n",
    "        return np.diag(factor_returns.var(axis=0, ddof=1) * ann_factor)\n",
    "    \n",
    "    # calculate idiosyncratic need to got factor_returns, factor_betas which calculate by pca model first\n",
    "    def idiosyncratic_var_matrix(self, returns, factor_returns, factor_betas, ann_factor):\n",
    "        estimate_returns = pd.DataFrame(np.dot(factor_returns, factor_betas.T), returns.index, returns.columns)\n",
    "        residuals = returns - estimate_returns\n",
    "        return pd.DataFrame(np.diag(np.var(residuals))*ann_factor, returns.columns, returns.columns)\n",
    "    \n",
    "    def plot_principle_risk(self):\n",
    "        # Make the bar plot\n",
    "        plt.bar(np.arange(self.num_factor_exposures), self.pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_df_by_day(df, start_time):\n",
    "    pca_time_window = len(df.loc[df['trade_date']<start_time].trade_date.unique())\n",
    "    print(f'pca window_len is {pca_time_window}')\n",
    "    #trade_date_list = df.loc[df['trade_date']>=start_time].trade_date.unique()\n",
    "    all_date_list = df.trade_date.unique()\n",
    "    for start_i in range(len(all_date_list)):\n",
    "        start_date = all_date_list[start_i]\n",
    "        if start_i + pca_time_window >= len(all_date_list):\n",
    "            break\n",
    "        end_date = all_date_list[start_i + pca_time_window]\n",
    "        yield df.loc[(df['trade_date']>=start_date) & (df['trade_date']<=end_date)]\n",
    "        \n",
    "def risk_by_PCA(returns_df):\n",
    "    # Set the number of factor exposures (principal components) for the PCA algorithm\n",
    "    num_factor_exposures = 5\n",
    "    # Create a RiskModel object\n",
    "    rm = RiskModel(returns_df, num_factor_exposures)\n",
    "    \n",
    "    B = rm.factor_betas_\n",
    "    F = rm.factor_cov_matrix_\n",
    "    S = rm.idiosyncratic_var_matrix_\n",
    "    f = rm.factor_returns_\n",
    "    \n",
    "    variance = np.dot(B, F).dot(B.T) + S\n",
    "    return variance, B, f, rm.idiosyncratic_var_vector\n",
    "\n",
    "# test\n",
    "start_time = 20220401\n",
    "df = next(rolling_df_by_day(all_factors, start_time))\n",
    "returns_df = df.pivot(index='trade_date', columns='ts_code', values='log-ret').fillna(0)\n",
    "variance_i, B, risk_factor, residual_i = risk_by_PCA(returns_df)\n",
    "df.loc[df.index[-1],'trade_date'].unique()[-1]\n",
    "risk_factor.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 20220401\n",
    "variance_all = {}\n",
    "residual_df = pd.DataFrame()\n",
    "\n",
    "for df in rolling_df_by_day(all_factors, start_time):\n",
    "    returns_df = df.pivot(index='trade_date', columns='ts_code', values='log-ret').fillna(0)\n",
    "    variance_i, B, risk_factor, residual_i = risk_by_PCA(returns_df)\n",
    "    variance_all[dt] = [variance_i, B, risk_factor.mean(axis=0)]\n",
    "    residual_i['trade_date'] = df.loc[df.index[-1],'trade_date'].unique()[-1]\n",
    "    residual_df = residual_df.append(residual_i)\n",
    "\n",
    "residual_df.reset_index(inplace=True)\n",
    "residual_df.columns = ['ts_code', 'residual', 'trade_date']\n",
    "residual_df['residual'] = np.where(residual_df['residual'].isnull(), residual_df['residual'].median(), residual_df['residual'])\n",
    "all_factors = all_factors.loc[all_factors['trade_date']>=start_time]\n",
    "all_factors = all_factors.merge(residual_df, on=['trade_date','ts_code'], how='left')\n",
    "#all_factors.tail()\n",
    "print(residual_df.shape, all_factors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_factors = all_factors.loc[all_factors['trade_date']>=start_time]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
