{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "In this notebook, We use data which I donwload from Tushare to make up some alpha factors and risk factors.\n",
    "1. Load data from Tushare time range bettwen 2017.1 - 2023.3.\n",
    "2. Calculate portfolio risk by PCA and save idiosynchritic values view a factor\n",
    "3. Make up some factors like we did in P4 project.\n",
    "5. Evaluate factor returns in 5D, 20D, 60D, 120D. and seperate factors into two parts, risk factors and alpha factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#universe_raw = pd.read_csv('raw_20170103_20230317.csv').iloc[:,1:]\n",
    "#fundamental_df = pd.read_csv('fundamental_20170103_20230317.csv').iloc[:,1:]\n",
    "universe_raw = pd.read_csv('tmp.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null to 0\n",
    "universe = universe_raw.copy(deep=True)\n",
    "universe['pb'] = np.where(universe_raw['pb'].isnull(), 0., universe_raw['pb'])\n",
    "universe['dt_eps'] = np.where(universe['dt_eps'].isnull(), 0., universe['dt_eps'])\n",
    "universe['dt_eps_yoy'] = np.where(universe['dt_eps_yoy'].isnull(), 0., universe['dt_eps_yoy'])\n",
    "# add typ value express\n",
    "universe['type_value2'] = np.where(universe['type_value']<0, -universe['type_value']/5, universe['type_value'])\n",
    "universe_raw = universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Explain\n",
    "  Fundamental indicators\n",
    "  - 'cfps','revenue_ps', 'quick_ratio',  每股现金流，每股营业收入，速冻比率\n",
    "  - 'dt_eps','basic_eps_yoy','dt_eps_yoy',  每股收益\n",
    "  - 'bps','bps_yoy',  每股净资产\n",
    "  - 'extra_item','profit_dedt', 扣非，扣非净利润\n",
    "  - 'roe_dt','q_dt_roe','roe_yoy',  净资产收益\n",
    "  - 'capital_rese_ps','surplus_rese_ps',  每股资本公积，每股公积盈余 \n",
    "  - 'gross_margin','interestdebt','ca_to_assets', 毛利，带息债务, 流动资产/总资产\n",
    "  - 'ebt_yoy','roe_yoy','or_yoy','equity_yoy' 总利润增长，净资产收益增长，营业收入增长，净资产增长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ts_code', 'trade_date', 'turnover_rate', 'volume_ratio', 'pe', 'pb',\n",
      "       'total_share', 'free_share', 'total_mv', 'circ_mv', 'name', 'industry',\n",
      "       'list_date', 'amount', 'adj_factor', 'open', 'close', 'high', 'low',\n",
      "       'macd', 'rsi_6', 'rsi_12', 'rsi_24', 'boll_upper', 'boll_mid',\n",
      "       'boll_lower', 'cci', 'date', 'pct_change', 'type', 'p_change_min',\n",
      "       'p_change_max', 'issue_price', 'issue_amount', 'type_value', 'cfps',\n",
      "       'revenue_ps', 'quick_ratio', 'dt_eps', 'basic_eps_yoy', 'dt_eps_yoy',\n",
      "       'bps', 'bps_yoy', 'extra_item', 'profit_dedt', 'roe_dt', 'q_dt_roe',\n",
      "       'roe_yoy', 'capital_rese_ps', 'surplus_rese_ps', 'gross_margin',\n",
      "       'interestdebt', 'ca_to_assets', 'ebt_yoy', 'roe_yoy.1', 'or_yoy',\n",
      "       'equity_yoy'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print(universe_raw.shape, len(fundamental_df.ts_code.unique()))\n",
    "print(universe.columns)\n",
    "#universe_raw.loc[universe_raw.ts_code=='603538.SH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Technology Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add volume\n",
    "universe_raw['volume'] = universe_raw['amount']/universe_raw['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stockstats\n",
    "\n",
    "class IndicatorHelper(pd.DataFrame):\n",
    "    \"\"\"\n",
    "        add indicators to dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super(IndicatorHelper, self).__init__(data)\n",
    "\n",
    "        self.stocks = stockstats.StockDataFrame.retype(data.copy())\n",
    "        self.df = self\n",
    "\n",
    "    def add_technical_indicator(self, tech_indicator_list):\n",
    "        \"\"\"\n",
    "        calculate technical indicators\n",
    "        use stockstats package to add technical inidactors\n",
    "        :param ticker: (df) pandas dataframe\n",
    "        :param tech_indeicator_list list\n",
    "        :return: (df) pandas dataframe\n",
    "        \"\"\"\n",
    "        unique_ticker = self.df.ts_code.unique()\n",
    "\n",
    "        indicator_df = pd.DataFrame()\n",
    "        for i in tqdm(range(len(unique_ticker)), desc='add tech indicators'):\n",
    "            temp_indicator = self.stocks[self.stocks.ts_code == unique_ticker[i]]\n",
    "            temp_indicator = temp_indicator[tech_indicator_list + ['ts_code','trade_date']]\n",
    "            indicator_df = indicator_df.append(temp_indicator, ignore_index=True)\n",
    "        \n",
    "        indicator_df = indicator_df.drop_duplicates(['trade_date','ts_code'])\n",
    "        self.df = self.df.merge(indicator_df, on=[\"ts_code\", \"trade_date\"], how=\"inner\")\n",
    "        self.df['date'] = pd.to_datetime(self.df['trade_date'],format='%Y%m%d')\n",
    "        self.df = self.df.set_index(['date']).sort_values(by=['date']).drop_duplicates(['trade_date','ts_code'])\n",
    "        return self.df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "add tech indicators: 100%|███████████████████████████████████████████████████████████| 122/122 [00:16<00:00,  7.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# add tech indicators\n",
    "tech_indicator_list = ['supertrend','close_5_sma','close_20_sma','close_60_sma',\n",
    "                       'log-ret','atr_5','cci_6', \n",
    "                       'close_10_kama_2_30', 'close_10_kama_5_30','close_2_kama'] \n",
    "universe = IndicatorHelper(universe_raw).add_technical_indicator(tech_indicator_list)\n",
    "# 'close_2_kama_20_mstd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructor Factors Based on Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supertrend Factors\n",
    "This factor based on supertrend and close 5 days sma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe['alpha_supertrend'] = universe['close_5_sma'] - universe['supertrend']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCI Factors\n",
    "This factor based on cci and atr 5 days window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe['alpha_cci'] = -np.where(universe['cci_6']>200, (universe['cci_6']-200)*universe['atr_5'], \\\n",
    "                      np.where(universe['cci_6']<-200, (universe['cci_6']+200)*universe['atr_5'], universe['atr_5']*30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KAMA Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kama filter: 100%|██████████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 167.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# add KAMA alpha factor\n",
    "def KAMA_filter(df):    \n",
    "    unique_stocks = df.ts_code.unique()\n",
    "    all_df = pd.DataFrame()\n",
    "    for ts_code in tqdm(unique_stocks, desc='kama filter'):\n",
    "        tmp = df.loc[df.ts_code == ts_code]\n",
    "        tmp['close_2_kama'] = tmp['close_2_kama'].fillna(method='ffill')\n",
    "        tmp['kama_filter'] = tmp['close_2_kama'].rolling(window=20).std().fillna(method='bfill') * 0.6\n",
    "        tmp['kama_prior'] = tmp['close_2_kama'].shift(-5).fillna(method='ffill')\n",
    "        tmp['alpha_kama'] = (tmp['close_10_kama_2_30'] - tmp['close_10_kama_5_30'])-(tmp['close_2_kama'] - tmp['kama_prior'] - tmp['kama_filter'])\n",
    "        #tmp['alpha_kama'] = -(tmp['close_2_kama'] - tmp['kama_prior'] - tmp['kama_filter'])\n",
    "        all_df = all_df.append(tmp[['ts_code','trade_date','alpha_kama']], ignore_index=True)\n",
    "    df = df.merge(all_df, on=['ts_code','trade_date'], how='left')\n",
    "    df['date'] = pd.to_datetime(df['trade_date'],format='%Y%m%d')\n",
    "    df = df.set_index(['date']).sort_values(by=['date'])\n",
    "    return df\n",
    "\n",
    "universe = KAMA_filter(universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructor Factors Based on Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overnight Return\n",
    "This factor we had did in P4\n",
    "\n",
    "$factor=(open_{today}-close_{yesterday})\\div close_{yesterday}$\n",
    "\n",
    "5 days sma of this factor as long factor and 20 sma as short factor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "close_to_open: 100%|████████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 228.53it/s]\n",
      "add tech indicators: 100%|██████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 187.23it/s]\n"
     ]
    }
   ],
   "source": [
    "class CloseToOpen(pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Overnight Return Factor Constructor\n",
    "    \"\"\"\n",
    "    def __init__(self,data):\n",
    "        super(CloseToOpen, self).__init__(data)\n",
    "        self.df = self\n",
    "\n",
    "    def calculate(self):\n",
    "        '''\n",
    "        add open-close as a column named close_to_return\n",
    "        :return: dataframe\n",
    "        '''\n",
    "        unique_ticker = self.df.ts_code.unique()\n",
    "        tmp_df = pd.DataFrame()\n",
    "        for ts_code in tqdm(unique_ticker, desc='close_to_open'):\n",
    "            stock = self.df.loc[self.df.ts_code == ts_code][[\"ts_code\", \"trade_date\", \"open\", \"close\"]]\n",
    "            stock['alpha_close2open'] = (stock['open'].shift(-1).fillna(method='ffill') - stock['close'])/stock['close']\n",
    "            tmp_df = tmp_df.append(stock, ignore_index=True)\n",
    "        self.df = self.df.merge(tmp_df[[\"ts_code\", \"trade_date\", \"alpha_close2open\"]], on=[\"ts_code\", \"trade_date\"], how=\"inner\")\n",
    "        self.df['date'] = pd.to_datetime(self.df['trade_date'], format='%Y%m%d')\n",
    "        self.df = self.df.set_index(['date']).sort_values(by=['date'])\n",
    "        return self\n",
    "    \n",
    "    def get_sma_factors(self):\n",
    "        '''\n",
    "        calculate close_to_open_5_sma, close_to_open_25_sma by IndicatorHelper class\n",
    "        :return: Dateframe\n",
    "        '''\n",
    "        self.df = IndicatorHelper(self.df).add_technical_indicator(['alpha_close2open_5_sma', 'alpha_close2open_20_sma'])\n",
    "        self.df['alpha_close2open_20_sma'] = - self.df['alpha_close2open_20_sma']\n",
    "        return self.df\n",
    "    \n",
    "\n",
    "universe = CloseToOpen(universe).calculate().get_sma_factors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winner And Loser\n",
    "This factor we also did in P4. It express a ticker how to reach a return in a spicific period time \n",
    "\n",
    "We use a time window as T, and regression d and v $return = T*d + T^2*v$  => $factor=d*v$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "winner and loser: 100%|██████████████████████████████████████████████████████████████| 122/122 [03:01<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "class WinnerAndLoser(pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Winner and Loser Factor Constructor\n",
    "    \"\"\"\n",
    "    def __init__(self,data, win_length=20):\n",
    "        super(WinnerAndLoser, self).__init__(data)\n",
    "        self.df = self\n",
    "        self.win_lenth = win_length\n",
    "\n",
    "    def _regression(self, data):\n",
    "        df = pd.DataFrame(data, columns=['log-ret'])\n",
    "        df['acc_ret'] = df['log-ret'].cumsum()\n",
    "        df['t_dir'] = np.arange(self.win_lenth)+1\n",
    "        df['t_velocity'] = df['t_dir'] ** 2\n",
    "        regression = ols(formula='acc_ret ~ 0 + t_dir + t_velocity', data=df)\n",
    "        model = regression.fit()\n",
    "        data['alpha_winlos'] = -model.params.t_dir * model.params.t_velocity\n",
    "        return  data['alpha_winlos']\n",
    "\n",
    "\n",
    "    def calculate(self):\n",
    "        '''\n",
    "        convert time to value\n",
    "        regress return to get mu and beta each time\n",
    "        add facotor mu*beta to colomns\n",
    "        :return: dataframe\n",
    "        '''\n",
    "        tickers = self.df.ts_code.unique()\n",
    "        factor_df = pd.DataFrame()\n",
    "        for ticker in tqdm(tickers, desc='winner and loser'):\n",
    "            tmp_df = self.df.loc[self.df.ts_code == ticker][['trade_date', 'ts_code', 'log-ret']]\n",
    "            tmp_df['alpha_winlos'] = tmp_df['log-ret'].rolling(self.win_lenth).apply(self._regression)\n",
    "            tmp_df['alpha_winlos'].fillna(method='bfill',inplace=True)\n",
    "            factor_df = factor_df.append(tmp_df, ignore_index=True)\n",
    "        self.df = self.df.merge(factor_df[[\"ts_code\", \"trade_date\", \"alpha_winlos\"]], on=[\"ts_code\", \"trade_date\"], how=\"left\")\n",
    "        self.df['date'] = pd.to_datetime(self.df['trade_date'],format='%Y%m%d')\n",
    "        self.df = self.df.set_index(['date']).sort_values(by=['date'])\n",
    "        return  self.df\n",
    "    \n",
    "    \n",
    "#test = universe.loc[universe.ts_code=='603538.SH']\n",
    "#test = universe.loc[universe.ts_code=='002038.SZ']\n",
    "#test = WinnerAndLoser(test).calculate()\n",
    "universe = WinnerAndLoser(universe).calculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew And Momentum\n",
    "This factor we also did in P4. It express minority and majority sentiment of investor how to impact on market.\n",
    "\n",
    "We calculate skew and median of log-return distribution in a period time, the skew view as marjority sentiment and median can view as minority sentiment.\n",
    "\n",
    "$factor = abs(skew) * median * volume\\_ratio$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skew and momentum: 100%|█████████████████████████████████████████████████████████████| 122/122 [00:08<00:00, 15.01it/s]\n"
     ]
    }
   ],
   "source": [
    "class SkewandMomentum(pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Expected Skewness and Momentum Factor Constructor\n",
    "    \"\"\"\n",
    "    def __init__(self,data, win_length=10):\n",
    "        super(SkewandMomentum, self).__init__(data)\n",
    "        self.df = self\n",
    "        self.win_length = win_length\n",
    "\n",
    "    def calculate(self):\n",
    "        '''\n",
    "        convert time to value\n",
    "        regress return to get mu and beta each time\n",
    "        add facotor mu*beta to colomns\n",
    "        :return: dataframe\n",
    "        '''\n",
    "        def calculate_factor(data):\n",
    "            return abs(data.skew()) * data.median()\n",
    "        \n",
    "        tmp_df = pd.DataFrame()\n",
    "        for stock_tuple in tqdm(self.groupby('ts_code'), desc='skew and momentum'):\n",
    "            stock = stock_tuple[1]\n",
    "            stock['alpha_skew2sentiment'] = stock['log-ret'].rolling(self.win_length).apply(calculate_factor)\n",
    "            stock['alpha_skew2sentiment'] = stock['alpha_skew2sentiment'].fillna(method='bfill') * stock['volume_ratio']/100\n",
    "            tmp_df = tmp_df.append(stock,ignore_index=True)\n",
    "        self.df = self.df.merge(tmp_df[[\"ts_code\", \"trade_date\", \"alpha_skew2sentiment\"]], on=[\"ts_code\", \"trade_date\"], how=\"left\")\n",
    "        self.df['date'] = pd.to_datetime(self.df['trade_date'],format='%Y%m%d')\n",
    "        self.df = self.df.set_index(['date']).sort_values(by=['date'])\n",
    "        return self.df\n",
    "\n",
    "\n",
    "#test = universe.loc[universe.ts_code=='603538.SH']\n",
    "#test = universe.loc[universe.ts_code=='002038.SZ']\n",
    "#test = SkewandMomentum(test).calculate()\n",
    "universe = SkewandMomentum(universe).calculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Factor\n",
    "This factor based on ticker fundamentals, it usually take a long period time to archive return. So called take a long line to catch a big fish! The factor we define as:\n",
    "\n",
    "$ factor1 = mean(turnover\\_5\\_windows) - std(turnover\\_25\\_windows)$\n",
    "\n",
    "$ factor2 = ((50 \\div pe) + (5 \\div pb)) * dt\\_eps * dt\\_eps\\_yoy * type_value / 50 $\n",
    "\n",
    "$ alpha\\_factor = factor1 * factor2 $\n",
    "\n",
    "- turnover_ratio: turnover ratio\n",
    "- pb: profit div balance\n",
    "- pe: profit div net balance\n",
    "- type_value: fundamentals prereport levels from -3 to 3\n",
    "- dt_eps: prifit each share of stock\n",
    "- dt_eps_yoy: profit increase percent of dt_esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fundamental factor: 100%|███████████████████████████████████████████████████████████| 122/122 [00:01<00:00, 119.34it/s]\n"
     ]
    }
   ],
   "source": [
    "def fundamentals_alpha_fundamental(df):\n",
    "    all_df = pd.DataFrame()\n",
    "    for ts_code in tqdm(df.ts_code.unique(), desc='fundamental factor'):\n",
    "        tmp = df.loc[df.ts_code==ts_code]\n",
    "        tmp['alpha_fundamental'] = (tmp['volume_ratio'].rolling(5).min().fillna(0) - tmp['volume_ratio'].rolling(20).std().fillna(0)) \n",
    "        tmp['alpha_fundamental'] = tmp['alpha_fundamental'] * (50/tmp['pe'] + 5/tmp['pb']) * \\\n",
    "                            (tmp['dt_eps'] * tmp['dt_eps_yoy'] / 50 * tmp['type_value'])\n",
    "        \n",
    "        all_df = all_df.append(tmp, ignore_index=True)\n",
    "        \n",
    "    df = df.merge(all_df[['ts_code','trade_date','alpha_fundamental']], on=['ts_code','trade_date'], how='left')\n",
    "    df['date'] = pd.to_datetime(df['trade_date'],format='%Y%m%d')\n",
    "    df = df.set_index(['date']).sort_values(by=['date'])\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "universe = fundamentals_alpha_fundamental(universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticker Pool\n",
    "After create factors we filte data by each day more in detail. \n",
    "\n",
    "We do this step after calculate factors in case of some tickers add in our portfolio calculate factor by historical data which not exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "tmp = universe_raw.loc[universe_raw.ts_code== '603538.SH']\n",
    "tmp = tmp.loc[(tmp['trade_date']>20180701) & (tmp['trade_date']<20200901)]\n",
    "#tmp[['close_5_sma','alpha_fundamental']] = tmp[['close_5_sma','alpha_fundamental']].apply(zscore)\n",
    "\n",
    "tmp['alpha'] = (tmp['volume_ratio'].rolling(5).mean().fillna(method='bfill')\n",
    "                 - tmp['volume_ratio'].rolling(20).std().fillna(0)) #\n",
    "tmp['alpha'] = tmp['alpha'] * (60/tmp['pe'] + 6/tmp['pb']) * (tmp['dt_eps'] * tmp['dt_eps_yoy'] / 100  * tmp['type_value'])\n",
    "#tmp['alpha'] = tmp['alpha'].rank(method='min', pct=True)\n",
    "tmp[['alpha']] = tmp[['alpha']].apply(zscore)\n",
    "\n",
    "tmp['close'] = tmp['close'] - 10\n",
    "#tmp[['alpha','close']].plot(grid=True)\n",
    "#tmp[['volume_ratio','volume_ratio_std','close']].plot(subplots=True, grid=True, figsize=(5, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
