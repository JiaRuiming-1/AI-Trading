{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "In this notebook, We use data which I donwload from Tushare to make up some alpha factors and risk factors.\n",
    "1. Load data from Tushare time range bettwen 2017.1 - 2023.3.\n",
    "2. Calculate portfolio risk by PCA and save idiosynchritic values view a factor\n",
    "3. Make up some factors like we did in P4 project.\n",
    "5. Evaluate factor returns in 5D, 20D, 60D, 120D. and seperate factors into two parts, risk factors and alpha factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#universe_raw = pd.read_csv('raw_20170103_20230317.csv').iloc[:,1:]\n",
    "#fundamental_df = pd.read_csv('fundamental_20170103_20230317.csv').iloc[:,1:]\n",
    "universe_raw = pd.read_csv('tmp.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null to 0\n",
    "universe = universe_raw.copy(deep=True)\n",
    "universe['pb'] = np.where(universe_raw['pb'].isnull(), 100., universe_raw['pb'])\n",
    "universe['dt_eps'] = np.where(universe['dt_eps'].isnull(), 0., universe['dt_eps'])\n",
    "universe['dt_eps_yoy'] = np.where(universe['dt_eps_yoy'].isnull(), 0., universe['dt_eps_yoy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Explain\n",
    "  Some data columns about fundamental indicators below\n",
    "  - 'cfps','revenue_ps', 'quick_ratio',  每股现金流，每股营业收入，速冻比率\n",
    "  - 'dt_eps','basic_eps_yoy','dt_eps_yoy',  每股收益\n",
    "  - 'bps','bps_yoy',  每股净资产\n",
    "  - 'extra_item','profit_dedt', 扣非，扣非净利润\n",
    "  - 'roe_dt','q_dt_roe','roe_yoy',  净资产收益\n",
    "  - 'capital_rese_ps','surplus_rese_ps',  每股资本公积，每股公积盈余 \n",
    "  - 'gross_margin','interestdebt','ca_to_assets', 毛利，带息债务, 流动资产/总资产\n",
    "  - 'ebt_yoy','roe_yoy','or_yoy','equity_yoy' 总利润增长，净资产收益增长，营业收入增长，净资产增长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overnight Return\n",
    "This factor we had did in P4, \n",
    "\n",
    "We calculate factor here, and add sma indicators later.\n",
    "\n",
    "$factor=(open_{today}-close_{yesterday})\\div close_{yesterday}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "close_to_open: 100%|████████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 285.14it/s]\n"
     ]
    }
   ],
   "source": [
    "class CloseToOpen(pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Overnight Return Factor Constructor\n",
    "    \"\"\"\n",
    "    def __init__(self,data):\n",
    "        super(CloseToOpen, self).__init__(data)\n",
    "        self.df = self\n",
    "\n",
    "    def calculate(self):\n",
    "        '''\n",
    "        add open-close as a column named close_to_return\n",
    "        :return: dataframe\n",
    "        '''\n",
    "        unique_ticker = self.df.ts_code.unique()\n",
    "        tmp_df = pd.DataFrame()\n",
    "        for ts_code in tqdm(unique_ticker, desc='close_to_open'):\n",
    "            stock = self.df.loc[self.df.ts_code == ts_code][[\"ts_code\", \"trade_date\", \"open\", \"close\"]]\n",
    "            stock['alpha_close2open'] = (stock['open'].shift(-1).fillna(method='ffill') - stock['close'])/stock['close']\n",
    "            tmp_df = tmp_df.append(stock, ignore_index=True)\n",
    "        self.df = self.df.merge(tmp_df[[\"ts_code\", \"trade_date\", \"alpha_close2open\"]], on=[\"ts_code\", \"trade_date\"], how=\"inner\")\n",
    "        self.df['date'] = pd.to_datetime(self.df['trade_date'], format='%Y%m%d')\n",
    "        self.df = self.df.set_index(['date']).sort_values(by=['date'])\n",
    "        return self.df\n",
    "    \n",
    "\n",
    "universe = CloseToOpen(universe).calculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Technology Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add volume\n",
    "universe['volume'] = universe['amount']/universe['close']\n",
    "universe = universe.drop_duplicates(['trade_date','ts_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stockstats\n",
    "\n",
    "class IndicatorHelper(pd.DataFrame):\n",
    "    \"\"\"\n",
    "        add indicators to dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super(IndicatorHelper, self).__init__(data)\n",
    "\n",
    "        self.stocks = stockstats.StockDataFrame.retype(data.copy())\n",
    "        self.df = self\n",
    "\n",
    "    def add_technical_indicator(self, tech_indicator_list):\n",
    "        \"\"\"\n",
    "        calculate technical indicators\n",
    "        use stockstats package to add technical inidactors\n",
    "        :param ticker: (df) pandas dataframe\n",
    "        :param tech_indeicator_list list\n",
    "        :return: (df) pandas dataframe\n",
    "        \"\"\"\n",
    "        unique_ticker = self.df.ts_code.unique()\n",
    "\n",
    "        indicator_df = pd.DataFrame()\n",
    "        for i in tqdm(range(len(unique_ticker)), desc='add tech indicators'):\n",
    "            temp_indicator = self.stocks[self.stocks.ts_code == unique_ticker[i]]\n",
    "            temp_indicator = temp_indicator[tech_indicator_list + ['ts_code','trade_date']]\n",
    "            indicator_df = indicator_df.append(temp_indicator, ignore_index=True)\n",
    "        \n",
    "        self.df = self.df.merge(indicator_df, on=[\"ts_code\", \"trade_date\"], how=\"inner\")\n",
    "        self.df['date'] = pd.to_datetime(self.df['trade_date'],format='%Y%m%d')\n",
    "        self.df = self.df.set_index(['date']).sort_values(by=['date']).drop_duplicates(['trade_date','ts_code'])\n",
    "        return self.df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "add tech indicators: 100%|███████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# add tech indicators\n",
    "tech_indicator_list = [\n",
    "                       'supertrend','close_5_sma','close_20_sma','close_60_sma',\n",
    "                       'log-ret','atr_5','cci_6', 'vwma_2','vwma_25',\n",
    "                       'close_10_kama_2_30', 'close_10_kama_5_30','close_2_kama',\n",
    "                       'alpha_close2open_5_sma', 'alpha_close2open_20_sma'\n",
    "                      ] \n",
    "universe = IndicatorHelper(universe).add_technical_indicator(tech_indicator_list)\n",
    "universe['alpha_close2open_20_sma'] = -universe['alpha_close2open_20_sma']\n",
    "# 'close_2_kama_20_mstd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructor Factors Based on Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supertrend Factors\n",
    "This factor based on supertrend and close 5 days sma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe['alpha_supertrend'] = universe['close_5_sma'] - universe['supertrend']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCI Factors\n",
    "This factor based on cci and atr 5 days window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe['alpha_cci'] = -np.where(universe['cci_6']>200, (universe['cci_6']-200)*universe['atr_5'], \\\n",
    "                      np.where(universe['cci_6']<-200, (universe['cci_6']+200)*universe['atr_5'], universe['atr_5']*30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KAMA Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kama filter: 100%|██████████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 167.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# add KAMA alpha factor\n",
    "def KAMA_filter(df):    \n",
    "    unique_stocks = df.ts_code.unique()\n",
    "    all_df = pd.DataFrame()\n",
    "    for ts_code in tqdm(unique_stocks, desc='kama filter'):\n",
    "        tmp = df.loc[df.ts_code == ts_code]\n",
    "        tmp['close_2_kama'] = tmp['close_2_kama'].fillna(method='ffill')\n",
    "        tmp['kama_filter'] = tmp['close_2_kama'].rolling(window=20).std().fillna(method='bfill') * 0.6\n",
    "        tmp['kama_prior'] = tmp['close_2_kama'].shift(-5).fillna(method='ffill')\n",
    "        tmp['alpha_kama'] = (tmp['close_10_kama_2_30'] - tmp['close_10_kama_5_30'])-(tmp['close_2_kama'] - tmp['kama_prior'] - tmp['kama_filter'])\n",
    "        #tmp['alpha_kama'] = -(tmp['close_2_kama'] - tmp['kama_prior'] - tmp['kama_filter'])\n",
    "        all_df = all_df.append(tmp[['ts_code','trade_date','alpha_kama']], ignore_index=True)\n",
    "    df = df.merge(all_df, on=['ts_code','trade_date'], how='left')\n",
    "    df['date'] = pd.to_datetime(df['trade_date'],format='%Y%m%d')\n",
    "    df = df.set_index(['date']).sort_values(by=['date'])\n",
    "    return df\n",
    "\n",
    "universe = KAMA_filter(universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructor Factors Based on Paper\n",
    "### Overnight Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we had add overnight return factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winner And Loser\n",
    "This factor we also did in P4. It express a ticker how to reach a return in a spicific period time \n",
    "\n",
    "We use a time window as T, and regression d and v $return = T*d + T^2*v$  => $factor=d*v$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "winner and loser: 100%|███████████████████████████| 1/1 [00:14<00:00, 14.97s/it]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "class WinnerAndLoser(pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Winner and Loser Factor Constructor\n",
    "    \"\"\"\n",
    "    def __init__(self,data, win_length=20):\n",
    "        super(WinnerAndLoser, self).__init__(data)\n",
    "        self.df = self\n",
    "        self.win_lenth = win_length\n",
    "\n",
    "    def _regression(self, data):\n",
    "        df = pd.DataFrame(data, columns=['log-ret'])\n",
    "        df['acc_ret'] = df['log-ret'].cumsum()\n",
    "        df['t_dir'] = np.arange(self.win_lenth)+1\n",
    "        df['t_velocity'] = df['t_dir'] ** 2\n",
    "        regression = ols(formula='acc_ret ~ 0 + t_dir + t_velocity', data=df)\n",
    "        model = regression.fit()\n",
    "        data['alpha_winlos'] = -model.params.t_dir * model.params.t_velocity\n",
    "        return  data['alpha_winlos']\n",
    "\n",
    "\n",
    "    def calculate(self):\n",
    "        '''\n",
    "        convert time to value\n",
    "        regress return to get mu and beta each time\n",
    "        add facotor mu*beta to colomns\n",
    "        :return: dataframe\n",
    "        '''\n",
    "        tickers = self.df.ts_code.unique()\n",
    "        factor_df = pd.DataFrame()\n",
    "        for ticker in tqdm(tickers, desc='winner and loser'):\n",
    "            tmp_df = self.df.loc[self.df.ts_code == ticker][['trade_date', 'ts_code', 'log-ret']]\n",
    "            tmp_df['alpha_winlos'] = tmp_df['log-ret'].rolling(self.win_lenth).apply(self._regression)\n",
    "            tmp_df['alpha_winlos'].fillna(method='bfill',inplace=True)\n",
    "            factor_df = factor_df.append(tmp_df, ignore_index=True)\n",
    "        self.df = self.df.merge(factor_df[[\"ts_code\", \"trade_date\", \"alpha_winlos\"]], on=[\"ts_code\", \"trade_date\"], how=\"left\")\n",
    "        self.df['date'] = pd.to_datetime(self.df['trade_date'],format='%Y%m%d')\n",
    "        self.df = self.df.set_index(['date']).sort_values(by=['date'])\n",
    "        return  self.df\n",
    "    \n",
    "    \n",
    "test = universe.loc[universe.ts_code=='603538.SH']\n",
    "#test = universe.loc[universe.ts_code=='002038.SZ']\n",
    "test = WinnerAndLoser(test).calculate()\n",
    "#universe = WinnerAndLoser(universe).calculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew And Momentum\n",
    "This factor we also did in P4. It express minority and majority sentiment of investor how to impact on market.\n",
    "\n",
    "We calculate skew and median of log-return distribution in a period time, the skew view as marjority sentiment and median can view as minority sentiment.\n",
    "\n",
    "$factor = abs(skew) * median * volume\\_ratio$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skew and momentum: 100%|█████████████████████████████████████████████████████████████| 122/122 [00:08<00:00, 14.93it/s]\n"
     ]
    }
   ],
   "source": [
    "class SkewandMomentum(pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Expected Skewness and Momentum Factor Constructor\n",
    "    \"\"\"\n",
    "    def __init__(self,data, win_length=10):\n",
    "        super(SkewandMomentum, self).__init__(data)\n",
    "        self.df = self\n",
    "        self.win_length = win_length\n",
    "\n",
    "    def calculate(self):\n",
    "        '''\n",
    "        convert time to value\n",
    "        regress return to get mu and beta each time\n",
    "        add facotor mu*beta to colomns\n",
    "        :return: dataframe\n",
    "        '''\n",
    "        def calculate_factor(data):\n",
    "            return abs(data.skew()) * data.median()\n",
    "        \n",
    "        tmp_df = pd.DataFrame()\n",
    "        for stock_tuple in tqdm(self.groupby('ts_code'), desc='skew and momentum'):\n",
    "            stock = stock_tuple[1]\n",
    "            stock['alpha_skew2sentiment'] = stock['log-ret'].rolling(self.win_length).apply(calculate_factor)\n",
    "            stock['alpha_skew2sentiment'] = stock['alpha_skew2sentiment'].fillna(method='bfill') * stock['volume_ratio']\n",
    "            tmp_df = tmp_df.append(stock,ignore_index=True)\n",
    "        self.df = self.df.merge(tmp_df[[\"ts_code\", \"trade_date\", \"alpha_skew2sentiment\"]], on=[\"ts_code\", \"trade_date\"], how=\"left\")\n",
    "        self.df['date'] = pd.to_datetime(self.df['trade_date'],format='%Y%m%d')\n",
    "        self.df = self.df.set_index(['date']).sort_values(by=['date'])\n",
    "        return self.df\n",
    "\n",
    "\n",
    "#test = universe.loc[universe.ts_code=='603538.SH']\n",
    "#test = universe.loc[universe.ts_code=='002038.SZ']\n",
    "#test = SkewandMomentum(test).calculate()\n",
    "universe = SkewandMomentum(universe).calculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Factor\n",
    "This factor based on ticker fundamentals, it usually take a long period time to archive return. So called take a long line to catch a big fish! The factor we define as:\n",
    "\n",
    "$ factor1 = mean(volume\\_5\\_windows) - std(volume\\_25\\_windows) * ((6 \\div pe) + (0.5 \\div pb)) * dt\\_eps$\n",
    "\n",
    "$ factor2 =  abs(dt\\_eps) * dt\\_eps\\_yoy * type\\_value \\div 30 $\n",
    "\n",
    "$ alpha\\_factor = factor1 + 0.3 * factor2 $\n",
    "\n",
    "- volume: trade volume\n",
    "- pb: profit div balance\n",
    "- pe: profit div net balance\n",
    "- type_value: fundamentals prereport levels from -3 to 3\n",
    "- dt_eps: prifit each share of stock\n",
    "- dt_eps_yoy: profit increase percent of dt_esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fundamental factor: 100%|████████████████████████████████████████████████████████████| 122/122 [00:01<00:00, 77.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "def fundamentals_alpha_fundamental(df):\n",
    "    all_df = pd.DataFrame()\n",
    "    for ts_code in tqdm(df.ts_code.unique(), desc='fundamental factor'):\n",
    "        tmp = df.loc[df.ts_code==ts_code]\n",
    "        tmp['alpha_fundamental1'] = (tmp['vwma_2'] - tmp['vwma_25'])* (6/tmp['pe'] + 0.5/tmp['pb'])*(tmp['dt_eps']**2)\n",
    "        tmp['alpha_fundamental2'] = np.where(tmp['dt_eps']>0, tmp['dt_eps'], 0.) * tmp['dt_eps_yoy'] / 100  * np.where(tmp['type_value']<0., 0.5, 2)\n",
    "        tmp[['alpha_fundamental1','alpha_fundamental2']] = tmp[['alpha_fundamental1','alpha_fundamental2']].apply(zscore)\n",
    "        tmp['alpha_fundamental'] = tmp['alpha_fundamental1'] + tmp['alpha_fundamental2'] \n",
    "        tmp['alpha_fundamental'].fillna(-1e-4,inplace = True)\n",
    "        all_df = all_df.append(tmp, ignore_index=True)\n",
    "        \n",
    "    df = df.merge(all_df[['ts_code','trade_date','alpha_fundamental']], on=['ts_code','trade_date'], how='left')\n",
    "    df['date'] = pd.to_datetime(df['trade_date'],format='%Y%m%d')\n",
    "    df = df.set_index(['date']).sort_values(by=['date'])\n",
    "    return df\n",
    "   \n",
    "#universe = universe.drop(columns=['alpha_fundamental'])\n",
    "universe = fundamentals_alpha_fundamental(universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticker Pool\n",
    "After create factors we filte data by each day more in detail. \n",
    "\n",
    "We do this step after calculate factors in case of some tickers add in our portfolio calculate factor by historical data which not exists.\n",
    "\n",
    "In real trade with this model factor use, download data each day, if you ensure add new tickers into portfolio, ensure get data 2 month ago at least, then calculate factos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "filter tikers: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:01<00:00, 154.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10607, 77) 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>turnover_rate</th>\n",
       "      <th>volume_ratio</th>\n",
       "      <th>pe</th>\n",
       "      <th>pb</th>\n",
       "      <th>total_share</th>\n",
       "      <th>free_share</th>\n",
       "      <th>total_mv</th>\n",
       "      <th>circ_mv</th>\n",
       "      <th>...</th>\n",
       "      <th>close_10_kama_2_30</th>\n",
       "      <th>close_10_kama_5_30</th>\n",
       "      <th>close_2_kama</th>\n",
       "      <th>alpha_close2open_5_sma</th>\n",
       "      <th>alpha_close2open_20_sma</th>\n",
       "      <th>alpha_supertrend</th>\n",
       "      <th>alpha_cci</th>\n",
       "      <th>alpha_kama</th>\n",
       "      <th>alpha_skew2sentiment</th>\n",
       "      <th>alpha_fundamental</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>300183.SZ</td>\n",
       "      <td>20180102</td>\n",
       "      <td>1.4832</td>\n",
       "      <td>0.72</td>\n",
       "      <td>25.4897</td>\n",
       "      <td>3.4960</td>\n",
       "      <td>47030.9857</td>\n",
       "      <td>20410.8707</td>\n",
       "      <td>9.086386e+05</td>\n",
       "      <td>5.090988e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>17.92257</td>\n",
       "      <td>17.92257</td>\n",
       "      <td>17.92257</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>-0.946240</td>\n",
       "      <td>-10.5756</td>\n",
       "      <td>0.142329</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.589884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>002435.SZ</td>\n",
       "      <td>20180102</td>\n",
       "      <td>0.3413</td>\n",
       "      <td>1.26</td>\n",
       "      <td>52.9549</td>\n",
       "      <td>1.6279</td>\n",
       "      <td>49077.6795</td>\n",
       "      <td>12274.2144</td>\n",
       "      <td>8.480623e+05</td>\n",
       "      <td>3.174855e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>6.44209</td>\n",
       "      <td>6.44209</td>\n",
       "      <td>6.44209</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>-0.005208</td>\n",
       "      <td>-0.184530</td>\n",
       "      <td>-1.6776</td>\n",
       "      <td>0.117876</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>1.814644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>300533.SZ</td>\n",
       "      <td>20180102</td>\n",
       "      <td>1.0670</td>\n",
       "      <td>0.86</td>\n",
       "      <td>32.6185</td>\n",
       "      <td>3.4140</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>3065.6779</td>\n",
       "      <td>5.071000e+05</td>\n",
       "      <td>1.818912e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>32.29039</td>\n",
       "      <td>32.29039</td>\n",
       "      <td>32.29039</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>-0.926490</td>\n",
       "      <td>-10.5066</td>\n",
       "      <td>0.071707</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>-0.786528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>002020.SZ</td>\n",
       "      <td>20180102</td>\n",
       "      <td>1.8545</td>\n",
       "      <td>0.49</td>\n",
       "      <td>39.8719</td>\n",
       "      <td>2.3107</td>\n",
       "      <td>73612.4472</td>\n",
       "      <td>43109.0368</td>\n",
       "      <td>8.450709e+05</td>\n",
       "      <td>5.584441e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>8.46846</td>\n",
       "      <td>8.46846</td>\n",
       "      <td>8.46846</td>\n",
       "      <td>-0.002613</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>-0.461025</td>\n",
       "      <td>-4.2045</td>\n",
       "      <td>-0.213766</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>1.236279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>002589.SZ</td>\n",
       "      <td>20180102</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.62</td>\n",
       "      <td>34.1563</td>\n",
       "      <td>2.6826</td>\n",
       "      <td>150471.0471</td>\n",
       "      <td>76256.2164</td>\n",
       "      <td>2.017817e+06</td>\n",
       "      <td>1.210350e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.16946</td>\n",
       "      <td>13.16946</td>\n",
       "      <td>13.16946</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>-0.584350</td>\n",
       "      <td>-6.1872</td>\n",
       "      <td>0.094116</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>1.856420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ts_code  trade_date  turnover_rate  volume_ratio       pe  \\\n",
       "date                                                                      \n",
       "2018-01-02  300183.SZ    20180102         1.4832          0.72  25.4897   \n",
       "2018-01-02  002435.SZ    20180102         0.3413          1.26  52.9549   \n",
       "2018-01-02  300533.SZ    20180102         1.0670          0.86  32.6185   \n",
       "2018-01-02  002020.SZ    20180102         1.8545          0.49  39.8719   \n",
       "2018-01-02  002589.SZ    20180102         0.6919          0.62  34.1563   \n",
       "\n",
       "                pb  total_share  free_share      total_mv       circ_mv  ...  \\\n",
       "date                                                                     ...   \n",
       "2018-01-02  3.4960   47030.9857  20410.8707  9.086386e+05  5.090988e+05  ...   \n",
       "2018-01-02  1.6279   49077.6795  12274.2144  8.480623e+05  3.174855e+05  ...   \n",
       "2018-01-02  3.4140   10000.0000   3065.6779  5.071000e+05  1.818912e+05  ...   \n",
       "2018-01-02  2.3107   73612.4472  43109.0368  8.450709e+05  5.584441e+05  ...   \n",
       "2018-01-02  2.6826  150471.0471  76256.2164  2.017817e+06  1.210350e+06  ...   \n",
       "\n",
       "           close_10_kama_2_30 close_10_kama_5_30  close_2_kama  \\\n",
       "date                                                             \n",
       "2018-01-02           17.92257           17.92257      17.92257   \n",
       "2018-01-02            6.44209            6.44209       6.44209   \n",
       "2018-01-02           32.29039           32.29039      32.29039   \n",
       "2018-01-02            8.46846            8.46846       8.46846   \n",
       "2018-01-02           13.16946           13.16946      13.16946   \n",
       "\n",
       "            alpha_close2open_5_sma  alpha_close2open_20_sma  alpha_supertrend  \\\n",
       "date                                                                            \n",
       "2018-01-02               -0.001035                 0.001035         -0.946240   \n",
       "2018-01-02                0.005208                -0.005208         -0.184530   \n",
       "2018-01-02               -0.000592                 0.000592         -0.926490   \n",
       "2018-01-02               -0.002613                 0.002613         -0.461025   \n",
       "2018-01-02                0.005220                -0.005220         -0.584350   \n",
       "\n",
       "            alpha_cci  alpha_kama  alpha_skew2sentiment  alpha_fundamental  \n",
       "date                                                                        \n",
       "2018-01-02   -10.5756    0.142329              0.000295          -0.589884  \n",
       "2018-01-02    -1.6776    0.117876              0.002603           1.814644  \n",
       "2018-01-02   -10.5066    0.071707              0.001470          -0.786528  \n",
       "2018-01-02    -4.2045   -0.213766             -0.000644           1.236279  \n",
       "2018-01-02    -6.1872    0.094116             -0.001022           1.856420  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove tickers by each day not exist history\n",
    "def remove_tickers(df, exist_ticker_list):\n",
    "    diff_df = df.loc[df.ts_code.isin(exist_ticker_list)==False]\n",
    "    if diff_df.empty == False:\n",
    "        # remove tickers not exist over 3month from day\n",
    "        diff1 = (pd.to_datetime(diff_df['trade_date'],format='%Y%m%d')\\\n",
    "                -pd.to_datetime(diff_df['list_date'],format='%Y%m%d')).apply(lambda x: x.days) < 90\n",
    "        # remove tickers pe > 80\n",
    "        diff2 = diff_df.pe > 80\n",
    "        # remove tickers pb > 10\n",
    "        diff3 = diff_df.pb > 10\n",
    "        # remove fundamental bad\n",
    "        diff4 = diff_df['type_value']<-1\n",
    "        # dt_eps <0 means profit is below 0.3 , remove it.\n",
    "        diff5 = diff_df['dt_eps']<0.3\n",
    "        # total_mv>50 billion\n",
    "        diff6 = diff_df['total_mv']>9000000\n",
    "        # get remove df\n",
    "        diff_df = diff_df.loc[diff1| diff2| diff3| diff4| diff5| diff6]\n",
    "        # get rest data\n",
    "        df = df.loc[df.ts_code.isin(diff_df.ts_code)==False]\n",
    "    return df\n",
    "\n",
    "# clean tickers pool day by day\n",
    "calendar = universe.trade_date.unique()\n",
    "universe_raw = pd.DataFrame()\n",
    "for dt in tqdm(calendar, desc='filter tikers'):\n",
    "    tmp = universe.loc[universe['trade_date']==dt]\n",
    "    if universe_raw.empty:\n",
    "        tmp = remove_tickers(tmp, [])\n",
    "    else:\n",
    "        tmp = remove_tickers(tmp, universe_raw.ts_code)\n",
    "    universe_raw = universe_raw.append(tmp, ignore_index=True)\n",
    "\n",
    "universe_raw['date'] = pd.to_datetime(universe_raw['trade_date'], format='%Y%m%d')\n",
    "universe_raw = universe_raw.set_index(['date']).sort_values(by=['date'])\n",
    "print(universe_raw.shape, len(universe_raw.ts_code.unique()))\n",
    "universe_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>turnover_rate</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>log-ret</th>\n",
       "      <th>pe</th>\n",
       "      <th>pb</th>\n",
       "      <th>amount</th>\n",
       "      <th>total_mv</th>\n",
       "      <th>...</th>\n",
       "      <th>ebt_yoy</th>\n",
       "      <th>or_yoy</th>\n",
       "      <th>equity_yoy</th>\n",
       "      <th>alpha_cci</th>\n",
       "      <th>alpha_kama</th>\n",
       "      <th>alpha_close2open</th>\n",
       "      <th>alpha_close2open_5_sma</th>\n",
       "      <th>alpha_close2open_20_sma</th>\n",
       "      <th>alpha_skew2sentiment</th>\n",
       "      <th>alpha_fundamental</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>300183.SZ</td>\n",
       "      <td>20180102</td>\n",
       "      <td>1.4832</td>\n",
       "      <td>17.82980</td>\n",
       "      <td>17.92257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.4897</td>\n",
       "      <td>3.4960</td>\n",
       "      <td>75186.17</td>\n",
       "      <td>9.086386e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.6280</td>\n",
       "      <td>-11.0714</td>\n",
       "      <td>8.0217</td>\n",
       "      <td>-10.5756</td>\n",
       "      <td>0.142329</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.589884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>002435.SZ</td>\n",
       "      <td>20180102</td>\n",
       "      <td>0.3413</td>\n",
       "      <td>6.48682</td>\n",
       "      <td>6.44209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.9549</td>\n",
       "      <td>1.6279</td>\n",
       "      <td>10849.69</td>\n",
       "      <td>8.480623e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0340</td>\n",
       "      <td>27.3816</td>\n",
       "      <td>498.6090</td>\n",
       "      <td>-1.6776</td>\n",
       "      <td>0.117876</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>-0.005208</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>1.814644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>300533.SZ</td>\n",
       "      <td>20180102</td>\n",
       "      <td>1.0670</td>\n",
       "      <td>32.34133</td>\n",
       "      <td>32.29039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.6185</td>\n",
       "      <td>3.4140</td>\n",
       "      <td>19345.40</td>\n",
       "      <td>5.071000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.8649</td>\n",
       "      <td>-21.4672</td>\n",
       "      <td>2.5131</td>\n",
       "      <td>-10.5066</td>\n",
       "      <td>0.071707</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>-0.786528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>002020.SZ</td>\n",
       "      <td>20180102</td>\n",
       "      <td>1.8545</td>\n",
       "      <td>8.54223</td>\n",
       "      <td>8.46846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.8719</td>\n",
       "      <td>2.3107</td>\n",
       "      <td>104010.18</td>\n",
       "      <td>8.450709e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>23.9800</td>\n",
       "      <td>14.5072</td>\n",
       "      <td>54.5084</td>\n",
       "      <td>-4.2045</td>\n",
       "      <td>-0.213766</td>\n",
       "      <td>-0.002613</td>\n",
       "      <td>-0.002613</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>1.236279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>002589.SZ</td>\n",
       "      <td>20180102</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>13.14982</td>\n",
       "      <td>13.16946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.1563</td>\n",
       "      <td>2.6826</td>\n",
       "      <td>83495.11</td>\n",
       "      <td>2.017817e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>123.9639</td>\n",
       "      <td>52.9144</td>\n",
       "      <td>12.9861</td>\n",
       "      <td>-6.1872</td>\n",
       "      <td>0.094116</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>1.856420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ts_code  trade_date  turnover_rate      open     close  log-ret  \\\n",
       "date                                                                            \n",
       "2018-01-02  300183.SZ    20180102         1.4832  17.82980  17.92257      0.0   \n",
       "2018-01-02  002435.SZ    20180102         0.3413   6.48682   6.44209      0.0   \n",
       "2018-01-02  300533.SZ    20180102         1.0670  32.34133  32.29039      0.0   \n",
       "2018-01-02  002020.SZ    20180102         1.8545   8.54223   8.46846      0.0   \n",
       "2018-01-02  002589.SZ    20180102         0.6919  13.14982  13.16946      0.0   \n",
       "\n",
       "                 pe      pb     amount      total_mv  ...   ebt_yoy   or_yoy  \\\n",
       "date                                                  ...                      \n",
       "2018-01-02  25.4897  3.4960   75186.17  9.086386e+05  ...  -33.6280 -11.0714   \n",
       "2018-01-02  52.9549  1.6279   10849.69  8.480623e+05  ...    6.0340  27.3816   \n",
       "2018-01-02  32.6185  3.4140   19345.40  5.071000e+05  ...  -43.8649 -21.4672   \n",
       "2018-01-02  39.8719  2.3107  104010.18  8.450709e+05  ...   23.9800  14.5072   \n",
       "2018-01-02  34.1563  2.6826   83495.11  2.017817e+06  ...  123.9639  52.9144   \n",
       "\n",
       "            equity_yoy alpha_cci alpha_kama  alpha_close2open  \\\n",
       "date                                                            \n",
       "2018-01-02      8.0217  -10.5756   0.142329         -0.001035   \n",
       "2018-01-02    498.6090   -1.6776   0.117876          0.005208   \n",
       "2018-01-02      2.5131  -10.5066   0.071707         -0.000592   \n",
       "2018-01-02     54.5084   -4.2045  -0.213766         -0.002613   \n",
       "2018-01-02     12.9861   -6.1872   0.094116          0.005220   \n",
       "\n",
       "            alpha_close2open_5_sma  alpha_close2open_20_sma  \\\n",
       "date                                                          \n",
       "2018-01-02               -0.001035                 0.001035   \n",
       "2018-01-02                0.005208                -0.005208   \n",
       "2018-01-02               -0.000592                 0.000592   \n",
       "2018-01-02               -0.002613                 0.002613   \n",
       "2018-01-02                0.005220                -0.005220   \n",
       "\n",
       "            alpha_skew2sentiment  alpha_fundamental  \n",
       "date                                                 \n",
       "2018-01-02              0.000295          -0.589884  \n",
       "2018-01-02              0.002603           1.814644  \n",
       "2018-01-02              0.001470          -0.786528  \n",
       "2018-01-02             -0.000644           1.236279  \n",
       "2018-01-02             -0.001022           1.856420  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter from 20170405\n",
    "# filte data columns as we use to next step\n",
    "field_list = [\n",
    "       'ts_code', 'trade_date', 'turnover_rate', 'open', 'close', 'log-ret', 'pe', 'pb','amount', 'total_mv', 'circ_mv', \n",
    "       'type', 'type_value', 'name', 'industry',\n",
    "       'issue_price', 'issue_amount', 'cfps','revenue_ps',\n",
    "       'quick_ratio', 'dt_eps', 'basic_eps_yoy', 'dt_eps_yoy',\n",
    "       'bps', 'bps_yoy', 'profit_dedt', 'roe_dt', 'q_dt_roe',\n",
    "       'roe_yoy', 'capital_rese_ps', 'surplus_rese_ps', 'gross_margin',\n",
    "       'interestdebt', 'ca_to_assets', 'ebt_yoy', 'or_yoy', 'equity_yoy', \n",
    "       'alpha_cci', 'alpha_kama', 'alpha_close2open',\n",
    "       'alpha_close2open_5_sma', 'alpha_close2open_20_sma',\n",
    "       'alpha_skew2sentiment', 'alpha_fundamental']\n",
    "universe_raw = universe_raw.loc[universe_raw['trade_date']>=20170405]\n",
    "universe_factors = universe_raw[field_list]\n",
    "universe_factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate idiosynchritic risk\n",
    "We calculate idiosynchritic risk of each tickers by each day\n",
    "\n",
    "$residual\\_ticker = \\sum_{i = ticker}tiker\\_return\\_i - \\frac{industry\\_marketcap}{total\\_marketcap} * industry\\_index\\_return$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag industry to 1 and 2, 1 to medicine_1000 index and rest to internet index\n",
    "def factors_from_names(n, name):\n",
    "    return list(filter(lambda x: name in x, n))\n",
    "\n",
    "universe_factors['industry_flag'] = np.where(universe_factors['industry'].isin(factors_from_names(universe_factors['industry'], '药')), 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index return\n",
    "def cal_index_return(df, index_df):\n",
    "    marketcap_total = df['total_mv'].sum()\n",
    "    industries = df.industry_flag.unique()\n",
    "    for flag in industries:\n",
    "        marketcap_industry = df.loc[df['industry_flag'] == flag]['total_mv'].sum()\n",
    "        index_return_val = (marketcap_industry / marketcap_total) * index_df[flag]\n",
    "        df.loc[df['industry_flag'] == flag]['index_return'] == index_return_val.values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 122\n"
     ]
    }
   ],
   "source": [
    "## save tmp data\n",
    "# fundamental_df.to_csv('fundamental_20170103_20230317.csv')\n",
    "# universe_raw.to_csv('raw_20170103_20230317.csv')\n",
    "# universe_factors.to_csv('factors_20170103_20230317.csv')\n",
    "\n",
    "## load universe_factors\n",
    "# universe_factors = pd.read_csv('tmp_factor.csv')\n",
    "# universe_factors['date'] = pd.to_datetime(universe_factors['date'],format='%Y-%m-%d')\n",
    "# universe_factors.set_index(['date'],inplace=True)\n",
    "\n",
    "print(len(universe_factors.ts_code.unique()), len(universe.ts_code.unique()))\n",
    "#universe_factors.loc[universe_factors.ts_code=='603538.SH'][['total_mv','dt_eps','dt_eps_yoy','type_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "tmp = universe_factors.loc[universe_factors.ts_code== '002649.SZ']\n",
    "#tmp = factor_df.loc[factor_df.ts_code== '002649.SZ']\n",
    "tmp[['alpha_kama','alpha_fundamental','close']] = tmp[['alpha_kama','alpha_fundamental','close']].apply(zscore,ddof=1).fillna(0.)\n",
    "\n",
    "#tmp['alpha'] = tmp['alpha'].rank(method='min', pct=True)\n",
    "tmp[['alpha_kama','alpha_fundamental']] = tmp[['alpha_kama','alpha_fundamental']]\n",
    "#tmp['alpha_fundamental'] = tmp['alpha_fundamental']\n",
    "tmp['close'] = tmp['close']\n",
    "tmp[['close','alpha_fundamental', 'alpha_kama']].plot(grid=True)\n",
    "#tmp[['close','alpha_fundamental']].plot(grid=True)\n",
    "#tmp[['vwma_5','vwma_25','close','vr_6']].plot(subplots=True, grid=True, figsize=(8, 10))\n",
    "#tmp[['vwma_5','vwma_25','close']].plot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
